{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajputaditya16/deepfake-Audio/blob/main/deepfake_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r8sZrUeICZx",
        "outputId": "e01d75a2-073c-4b01-8313-e312d7b0878a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/birdy654/deep-voice-deepfake-voice-recognition?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 2.55G/3.69G [01:59<00:58, 20.9MB/s]"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"birdy654/deep-voice-deepfake-voice-recognition\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SWvUczKko7V"
      },
      "outputs": [],
      "source": [
        "!pip install resampy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5jUHlhLj4id"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import IPython\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation,Reshape,MaxPooling2D, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdH4Ig3kkL-1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "paths = []\n",
        "labels = []\n",
        "\n",
        "# Define the root directory\n",
        "root_dir = '/root/.cache/kagglehub/datasets/birdy654/deep-voice-deepfake-voice-recognition/versions/2'\n",
        "\n",
        "# Iterate through the subdirectories\n",
        "for subdir in os.listdir(root_dir):\n",
        "    subdir_path = os.path.join(root_dir, subdir)\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(subdir_path):\n",
        "        # Add all files in the subdirectory\n",
        "        for filename in os.listdir(subdir_path):\n",
        "            file_path = os.path.join(subdir_path, filename)\n",
        "            paths.append(file_path)\n",
        "            # Add label based on the subdirectory name\n",
        "            labels.append(subdir)\n",
        "\n",
        "print('Dataset is loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuIb4rEzmFld"
      },
      "outputs": [],
      "source": [
        "len(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS8_MNm2mH1c"
      },
      "outputs": [],
      "source": [
        "paths[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UqrPCT6mN8R"
      },
      "outputs": [],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phlF-suKmWgY"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['speech'] = paths\n",
        "df['label'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJcV1qSJmep3"
      },
      "outputs": [],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-5hifuCmkcN"
      },
      "outputs": [],
      "source": [
        "audio_path = '/root/.cache/kagglehub/datasets/birdy654/deep-voice-deepfake-voice-recognition/versions/2'\n",
        "real_audio_path = 'REAL'\n",
        "fake_audio_path = 'FAKE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1D62PGsm3Y6"
      },
      "outputs": [],
      "source": [
        "folders = os.listdir(audio_path)\n",
        "print(folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WfflZy7nAaX"
      },
      "outputs": [],
      "source": [
        "real_audio = '/root/.cache/kagglehub/datasets/birdy654/deep-voice-deepfake-voice-recognition/versions/2/KAGGLE/AUDIO/REAL/biden-original.wav'\n",
        "fake_audio = '/root/.cache/kagglehub/datasets/birdy654/deep-voice-deepfake-voice-recognition/versions/2/KAGGLE/AUDIO/FAKE/linus-to-biden.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rbasfn_nE-O"
      },
      "outputs": [],
      "source": [
        "print('Real Audio:')\n",
        "IPython.display.Audio(real_audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpc8pIoDoqYQ"
      },
      "outputs": [],
      "source": [
        "print('Fake Audio:')\n",
        "IPython.display.Audio(fake_audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agOT4602o1zi"
      },
      "outputs": [],
      "source": [
        "real_ad, real_sr = librosa.load(real_audio)\n",
        "plt.figure(figsize= (12,4))\n",
        "plt.plot(real_ad)\n",
        "plt.title('Real Audio Data',\n",
        "          fontsize = 40)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goayk7eQpx8r"
      },
      "outputs": [],
      "source": [
        "real_spec = np.abs(librosa.stft(real_ad))\n",
        "real_spec = librosa.amplitude_to_db(real_spec, ref = np.max)\n",
        "plt.figure(figsize=(14,5))\n",
        "librosa.display.specshow(real_spec, sr = real_sr, x_axis = 'time', y_axis = 'log')\n",
        "plt.colorbar(format = '%+2.0f dB')\n",
        "plt.title(\"Real Audio Spectogram\",\n",
        "          fontsize = 40)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sey97FFsrFFn"
      },
      "outputs": [],
      "source": [
        "real_mel_spect = librosa.feature.melspectrogram(y = real_ad, sr = real_sr)\n",
        "real_mel_spect = librosa.power_to_db(real_mel_spect, ref = np.max)\n",
        "plt.figure(figsize = (14,5))\n",
        "librosa.display.specshow(real_mel_spect, y_axis ='mel', x_axis = 'time')\n",
        "plt.title('Real Audio Mel Spectogram')\n",
        "plt.colorbar(format = '%+2.0f dB')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_chroma = librosa.feature.chroma_cqt(y = real_ad, sr = real_sr, bins_per_octave=36)\n",
        "plt.figure(figsize = (14, 5))\n",
        "librosa.display.specshow(real_chroma, sr = real_sr, x_axis = 'time', y_axis = 'chroma', vmin = 0, vmax = 1)\n",
        "plt.colorbar()\n",
        "plt.title('Real Audio Chormagram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3J4B_4PCufcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_mfcc = librosa.feature.mfcc(y = real_ad, sr = real_sr)\n",
        "plt.figure(figsize = (14,5))\n",
        "librosa.display.specshow(real_mfcc, sr = real_sr, x_axis ='time')\n",
        "plt.colorbar()\n",
        "plt.title('Real Audio Mel-Frequency Cepstral Ceofficients (MFCCS)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JdX_fsJzuH3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_ad, fake_sr = librosa.load(fake_audio)\n",
        "plt.figure(figsize =(6,2))\n",
        "plt.plot(fake_ad)\n",
        "plt.title(\"Fake Audio Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m2xFpziVuH5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_spec = np.abs(librosa.stft(fake_ad))\n",
        "fake_spec = librosa.amplitude_to_db(fake_spec, ref = np.max)\n",
        "plt.figure(figsize=(14,5))\n",
        "librosa.display.specshow(fake_spec, sr = fake_sr, x_axis = 'time', y_axis = 'log')\n",
        "plt.colorbar(format = '%+2.0f dB')\n",
        "plt.title(\"Real Fake Spectogram\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F7VIIUwFuH7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_mel_spect = librosa.feature.melspectrogram(y = fake_ad, sr = fake_sr)\n",
        "fake_mel_spect = librosa.power_to_db(fake_mel_spect, ref = np.max)\n",
        "plt.figure(figsize = (14,5))\n",
        "librosa.display.specshow(fake_mel_spect, y_axis ='mel', x_axis = 'time')\n",
        "plt.title('Fake Audio Mel Spectogram')\n",
        "plt.colorbar(format = '%+2.0f dB')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QOZfIBZZuH-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_chroma = librosa.feature.chroma_cqt(y = fake_ad, sr = fake_sr, bins_per_octave=36)\n",
        "plt.figure(figsize=(14,5))\n",
        "librosa.display.specshow(fake_chroma, sr = fake_sr, x_axis= 'time', y_axis = 'chroma', vmin = 0, vmax = 1)\n",
        "plt.colorbar()\n",
        "plt.title('Fake Audio Chromagram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LxA4rZwLuIA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_mfcc = librosa.feature.mfcc(y = fake_ad, sr = fake_sr)\n",
        "plt.figure(figsize = (14,5))\n",
        "librosa.display.specshow(fake_mfcc, sr = fake_sr, x_axis ='time')\n",
        "plt.colorbar()\n",
        "plt.title('Fake Audio Mel-Frequency Cepstral Ceofficients (MFCCS)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tEdYi3nHuIDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "def extract_features(audio_path, max_length=500):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for folder in os.listdir(audio_path):\n",
        "        folder_path = os.path.join(audio_path, folder)\n",
        "        for file in tqdm(os.listdir(folder_path)):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "                # Load audio file\n",
        "                audio, _ = librosa.load(file_path, sr=16000)\n",
        "                # Extract features (example: using Mel-Frequency Cepstral Coefficients)\n",
        "                mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n",
        "                # Pad or trim the feature array to a fixed length\n",
        "                if mfccs.shape[1] < max_length:\n",
        "                    mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')\n",
        "                else:\n",
        "                  mfccs = mfccs[:, :max_length]\n",
        "                  features.append(mfccs)\n",
        "                # Assign label\n",
        "                if folder == 'FAKE':\n",
        "                    labels.append(1)  # 1 for fake\n",
        "                else:\n",
        "                    labels.append(0)  # 0 for real\n",
        "            except Exception as e:\n",
        "                print(f\"Error encountered while parsing file: {file_path}\")\n",
        "                continue\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Example usage\n",
        "audio_path = '/kaggle/input/deep-voice-deepfake-voice-recognition/KAGGLE/AUDIO'\n",
        "x, y = extract_features(audio_path)\n",
        "\n",
        "print(\"Features shape:\", x.shape)\n",
        "print(\"Labels shape:\", y.shape)"
      ],
      "metadata": {
        "id": "nI2bL9fXuIF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.1)"
      ],
      "metadata": {
        "id": "buAKHyS6uIJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Reshape((40, 500, 1), input_shape=xtrain.shape[1:]),  # Reshape input to add channel dimension\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "yfP6toqQviX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics  = ['accuracy'])"
      ],
      "metadata": {
        "id": "nJH-L1nlvi-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain, ytrain, epochs = 200, batch_size = 32, validation_data = [xtest,ytest])"
      ],
      "metadata": {
        "id": "WUjx32QYvjCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy = model.evaluate(xtest,ytest)"
      ],
      "metadata": {
        "id": "JkW6-MQzvyl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix, roc_curve"
      ],
      "metadata": {
        "id": "n69WpRmIvyoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ypred = np.round(model.predict(xtest))\n",
        "val_acc = accuracy_score(ypred, ytest)\n",
        "\n",
        "print(f\"Accuracy: {val_acc*100: .2f}%\")"
      ],
      "metadata": {
        "id": "LrTQnmZMvyq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(ytest, ypred)\n",
        "f1 = f1_score(ytest, ypred)\n",
        "recall = recall_score(ytest, ypred)\n",
        "precision = precision_score(ytest, ypred)"
      ],
      "metadata": {
        "id": "RKKY2gbqvytM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"F1 Score: \", f1)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)"
      ],
      "metadata": {
        "id": "DgQqmgHyvyvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")"
      ],
      "metadata": {
        "id": "X3yC5EfSwASC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(ytest, ypred))"
      ],
      "metadata": {
        "id": "jRtKOYljwAUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# print confusion matrix\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Fake\", \"Real\"], yticklabels=[\"Fake\", \"Real\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MmRBl0rDwAX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 10 -r 3  np.round(model.predict(xtest))"
      ],
      "metadata": {
        "id": "cKbFrj6ivyzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kg7M4J9wNzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VjVNQaOwN1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28hPE2WfwN33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9urH0H6wN51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUKkBrQKwN9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMw3R2KJPOgm4PIUES0mcxU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}